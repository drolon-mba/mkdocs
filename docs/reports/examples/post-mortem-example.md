## ğŸ’€ Post-Mortem Report

### â„¹ï¸ Meta InformaciÃ³n
- **Incidente:** CaÃ­da de Checkout en Black Friday
- **Fecha:** 2025-11-24
- **Estado:** Final
- **Autores:** Juan Perez, Maria Garcia
- **Severidad:** SEV-1

---

### ğŸ“ Resumen Ejecutivo
Durante el pico de trÃ¡fico de Black Friday, el servicio de Checkout comenzÃ³ a responder con errores 503 debido a agotamiento de conexiones a la base de datos. El incidente durÃ³ 15 minutos, afectando al 100% de los intentos de compra. Se resolviÃ³ aumentando el pool de conexiones y reiniciando los pods.

---

### ğŸ“Š Impacto
- **DuraciÃ³n:** 15 minutos (14:00 - 14:15 UTC)
- **Usuarios afectados:** ~5,000 intentos de compra fallidos
- **PÃ©rdida estimada:** ~$150,000 USD
- **SLA Breached:** SÃ­

---

### ğŸ•’ Timeline
_Todas las horas en UTC_

- **[14:00]** - Alerta de "High Error Rate" en Checkout Service dispara en PagerDuty.
- **[14:02]** - On-call (Juan) reconoce alerta y entra al war room.
- **[14:05]** - Logs muestran `ConnectionPoolTimeoutException`.
- **[14:07]** - DB Metrics muestran 100% conexiones activas.
- **[14:09]** - DecisiÃ³n: Escalar pool size en config y reiniciar.
- **[14:12]** - Deploy de config map actualizado.
- **[14:15]** - Servicio recuperado, error rate baja a 0%.

---

### ğŸ” Causa RaÃ­z (5 Whys)
1. **Â¿Por quÃ© fallÃ³ el checkout?**
   La base de datos rechazÃ³ nuevas conexiones.
2. **Â¿Por quÃ© rechazÃ³ conexiones?**
   Se alcanzÃ³ el lÃ­mite mÃ¡ximo configurado (max_connections=100).
3. **Â¿Por quÃ© se alcanzÃ³ el lÃ­mite?**
   El trÃ¡fico fue 5x lo normal y cada request abrÃ­a una conexiÃ³n nueva.
4. **Â¿Por quÃ© cada request abrÃ­a conexiÃ³n nueva?**
   El servicio no estaba reusando conexiones eficientemente (connection leak en un endpoint legado).
5. **Â¿Por quÃ© no se detectÃ³ en pruebas de carga?**
   Las pruebas de carga usaron el flujo nuevo, no el endpoint legado que recibiÃ³ trÃ¡fico inesperado.

---

### ğŸ› ï¸ ResoluciÃ³n y RecuperaciÃ³n
Se aumentÃ³ temporalmente el lÃ­mite de conexiones de la DB y del pool de la aplicaciÃ³n. Se identificÃ³ el endpoint problemÃ¡tico y se deshabilitÃ³ temporalmente hasta fixearlo.

---

### ğŸ“ Lecciones Aprendidas
**Lo que saliÃ³ bien:**
- El equipo reaccionÃ³ en < 2 minutos.
- El dashboard de mÃ©tricas de DB fue claro.

**Lo que saliÃ³ mal:**
- No tenÃ­amos un "Kill Switch" para el endpoint legado.
- Las pruebas de carga no cubrieron escenarios legacy.

---

### âœ… Action Items
| Tarea | Tipo | DueÃ±o | Prioridad | Ticket |
|:------|:-----|:------|:----------|:-------|
| Fix connection leak en LegacyCheckout | ReparaciÃ³n | @backend | CrÃ­tica | JIRA-501 |
| Incluir flujos legacy en Load Tests | Preventivo | @qa | Alta | JIRA-502 |
| Implementar PgBouncer para pooling | Arquitectura | @sre | Media | JIRA-503 |
