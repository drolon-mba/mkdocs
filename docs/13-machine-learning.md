# 13 - Machine Learning y Deep Learning

> Sistemas que aprenden de datos para hacer predicciones, clasificaciones y generaci√≥n de contenido.

[üè† Volver al √≠ndice](./00-indice.md)

---

## ü§ñ Machine Learning

**What:** Algoritmos que mejoran con experiencia sin ser programados expl√≠citamente.

**Why:** Automatizar decisiones, encontrar patrones, personalizaci√≥n.

**Who:** Data Scientists, ML Engineers, Research Engineers.

**How much:** Alta inversi√≥n inicial (datos, entrenamiento), ROI variable seg√∫n caso de uso.

---

## üìä Tipos de Aprendizaje

| Tipo | What | When | Algoritmos |
|:-----|:-----|:-----|:-----------|
| **Supervisado** | Aprender de datos etiquetados | Clasificaci√≥n, regresi√≥n | Linear Regression, Random Forest, XGBoost, SVM |
| **No Supervisado** | Encontrar patrones sin etiquetas | Clustering, reducci√≥n dimensionalidad | K-Means, DBSCAN, PCA, t-SNE |
| **Semi-Supervisado** | Pocos labels + muchos unlabeled | Etiquetado costoso | Self-training, co-training |
| **Reinforcement Learning** | Aprender por reward/penalty | Gaming, rob√≥tica, trading | Q-Learning, DQN, PPO, A3C |

---

## üß† Algoritmos Cl√°sicos (ML)

| Algoritmo | What | When | Pros/Cons |
|:----------|:-----|:-----|:----------|
| **Linear Regression** | Predecir valor continuo | Relaci√≥n lineal | ‚úÖ Simple, interpretable<br>‚ùå Solo lineal |
| **Logistic Regression** | Clasificaci√≥n binaria | Baseline classification | ‚úÖ R√°pido, probabil√≠stico<br>‚ùå Solo linealmente separable |
| **Decision Trees** | √Årbol de decisiones | Interpretabilidad | ‚úÖ F√°cil explicar<br>‚ùå Overfitting |
| **Random Forest** | Ensemble de √°rboles | Clasificaci√≥n/regresi√≥n robusta | ‚úÖ Reduce overfitting<br>‚ùå Menos interpretable |
| **XGBoost** | Gradient boosting optimizado | Competencias Kaggle | ‚úÖ SOTA en tabular<br>‚ùå Tuning complejo |
| **SVM** | Support Vector Machines | Clasificaci√≥n con kernel | ‚úÖ Efectivo high-dim<br>‚ùå Lento en big data |
| **K-Means** | Clustering por centroides | Segmentaci√≥n clientes | ‚úÖ Simple<br>‚ùå Requiere K predefinido |
| **PCA** | Reducci√≥n dimensionalidad | Visualizaci√≥n, preprocessing | ‚úÖ Elimina colinealidad<br>‚ùå Pierde interpretabilidad |

**Herramientas:** [scikit-learn](https://scikit-learn.org/), [XGBoost](https://xgboost.readthedocs.io/), [LightGBM](https://lightgbm.readthedocs.io/)

---

## üß† Deep Learning

**What:** Redes neuronales con m√∫ltiples capas.

**Why:** Aprende representaciones complejas, SOTA en visi√≥n, NLP, audio.

| Arquitectura | What | When | Use Cases |
|:-------------|:-----|:-----|:----------|
| **CNN** (Convolutional) | Redes para datos espaciales | Im√°genes, video | Clasificaci√≥n im√°genes, detecci√≥n objetos |
| **RNN** (Recurrent) | Redes para secuencias | Series temporales, texto | Predicci√≥n series, sentiment analysis |
| **LSTM** (Long Short-Term Memory) | RNN con memoria long-term | Secuencias largas | Traducci√≥n, generaci√≥n texto |
| **Transformer** | Attention mechanism | NLP moderno | BERT, GPT, traducci√≥n |
| **GAN** (Generative Adversarial) | Generador vs Discriminador | Generar im√°genes realistas | Deepfakes, data augmentation |
| **Autoencoder** | Encoder-Decoder | Reducci√≥n dimensionalidad, denoising | Compresi√≥n, anomal√≠as |
| **Diffusion Models** | Generaci√≥n iterativa | Generaci√≥n imagen SOTA | DALL-E, Stable Diffusion |

**Frameworks:** [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), [Keras](https://keras.io/), [JAX](https://github.com/google/jax)

---

## üó£Ô∏è NLP (Natural Language Processing)

| Tarea | What | Modelos |
|:------|:-----|:--------|
| **Clasificaci√≥n texto** | Categorizar documentos | BERT, RoBERTa, DistilBERT |
| **NER** (Named Entity Recognition) | Extraer entidades | spaCy, Flair |
| **Sentiment Analysis** | Detectar sentimiento | Fine-tuned BERT |
| **Traducci√≥n** | Traducir entre idiomas | mT5, MarianMT |
| **Question Answering** | Responder preguntas | BERT-QA, T5 |
| **Text Generation** | Generar texto coherente | GPT-4, Claude, LLaMA |
| **Embeddings** | Vectorizar texto | Word2Vec, GloVe, BERT embeddings |

**Herramientas:** [Hugging Face](https://huggingface.co/), [spaCy](https://spacy.io/), [LangChain](https://www.langchain.com/)

---

## üëÅÔ∏è Computer Vision

| Tarea | What | Modelos |
|:------|:-----|:--------|
| **Clasificaci√≥n** | Etiquetar imagen | ResNet, EfficientNet, Vision Transformer |
| **Detecci√≥n objetos** | Ubicar objetos en imagen | YOLO, Faster R-CNN |
| **Segmentaci√≥n** | Clasificar cada pixel | U-Net, Mask R-CNN |
| **Pose Estimation** | Detectar posici√≥n humana | OpenPose, MediaPipe |
| **OCR** | Extraer texto de imagen | Tesseract, EasyOCR |
| **Face Recognition** | Identificar personas | FaceNet, ArcFace |

**Herramientas:** [OpenCV](https://opencv.org/), [YOLO](https://github.com/ultralytics/ultralytics), [MediaPipe](https://mediapipe.dev/)

---

## üîÑ MLOps

**What:** DevOps para Machine Learning (automatizar pipeline ML).

**Why:** Reproducibilidad, deployment continuo, monitoreo modelos.

| Fase | What | Herramientas |
|:-----|:-----|:-------------|
| **Experiment Tracking** | Registrar entrenamientos | [MLflow](https://mlflow.org/), [Weights & Biases](https://wandb.ai/) |
| **Feature Store** | Centralizar features | [Feast](https://feast.dev/), [Tecton](https://www.tecton.ai/) |
| **Model Registry** | Versionar modelos | MLflow, [DVC](https://dvc.org/) |
| **Training** | Pipeline entrenamiento | [Kubeflow](https://www.kubeflow.org/), [SageMaker](https://aws.amazon.com/sagemaker/) |
| **Serving** | Deploy modelos | [TorchServe](https://pytorch.org/serve/), [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving) |
| **Monitoring** | Detectar drift | [Evidently](https://www.evidentlyai.com/), [WhyLabs](https://whylabs.ai/) |

---

## üìä Pipeline ML

```
1. Problem Definition
   ‚Üì
2. Data Collection
   ‚Üì
3. Data Cleaning & EDA
   ‚Üì
4. Feature Engineering
   ‚Üì
5. Model Training
   ‚Üì
6. Evaluation (test set)
   ‚Üì
7. Hyperparameter Tuning
   ‚Üì
8. Deployment
   ‚Üì
9. Monitoring & Retraining
```

---

## üéØ Evaluaci√≥n de Modelos

### Clasificaci√≥n

| M√©trica | What | When |
|:--------|:-----|:-----|
| **Accuracy** | % correctos | Clases balanceadas |
| **Precision** | % de positivos correctos | Minimizar falsos positivos |
| **Recall** | % de positivos encontrados | Minimizar falsos negativos |
| **F1-Score** | Media arm√≥nica precision/recall | Balance |
| **ROC-AUC** | √Årea bajo curva ROC | Evaluar probabilidades |
| **Confusion Matrix** | Visualizar errores | Entender errores |

### Regresi√≥n

| M√©trica | What | When |
|:--------|:-----|:-----|
| **MAE** | Mean Absolute Error | Interpretar error promedio |
| **MSE** | Mean Squared Error | Penalizar errores grandes |
| **RMSE** | Root MSE | Misma escala que target |
| **R¬≤** | Varianza explicada | Comparar modelos |

---

## üîß Feature Engineering

| T√©cnica | What | Ejemplo |
|:--------|:-----|:--------|
| **Encoding** | Convertir categ√≥ricas | One-hot, label encoding |
| **Scaling** | Normalizar rangos | StandardScaler, MinMaxScaler |
| **Binning** | Discretizar continuas | Edad ‚Üí grupos etarios |
| **Interactions** | Combinar features | precio * cantidad |
| **Time Features** | Extraer de fechas | d√≠a_semana, mes, hora |
| **Text Features** | De texto a n√∫meros | TF-IDF, embeddings |

---

## ‚öôÔ∏è Optimizaci√≥n Hiperpar√°metros

| M√©todo | What | When |
|:-------|:-----|:-----|
| **Grid Search** | Probar todas combinaciones | Pocos hiperpar√°metros |
| **Random Search** | Sampling aleatorio | M√°s hiperpar√°metros |
| **Bayesian Optimization** | Optimizaci√≥n inteligente | Entrenamientos costosos |
| **Optuna** | AutoML hyperparameter tuning | Automatizar b√∫squeda |

**Herramientas:** [Optuna](https://optuna.org/), [Ray Tune](https://docs.ray.io/en/latest/tune/index.html), [Hyperopt](http://hyperopt.github.io/hyperopt/)

---

## üß™ Validaci√≥n

| T√©cnica | What | When |
|:--------|:-----|:-----|
| **Train/Test Split** | 80-20 o 70-30 | Dataset suficientemente grande |
| **K-Fold CV** | K subsets, entrenar K veces | Datasets peque√±os |
| **Stratified K-Fold** | Mantener proporci√≥n clases | Clases desbalanceadas |
| **Time Series Split** | No mezclar temporal | Series temporales |

---

## üö´ Problemas Comunes

| Problema | Causa | Soluci√≥n |
|:---------|:------|:---------|
| **Overfitting** | Modelo memoriza training | Regularization, m√°s datos, dropout |
| **Underfitting** | Modelo muy simple | M√°s features, modelo m√°s complejo |
| **Data Leakage** | Info de test en training | Validar splits, feature engineering post-split |
| **Imbalanced Classes** | 99% clase A, 1% clase B | Oversampling (SMOTE), class weights |
| **Concept Drift** | Distribuci√≥n cambia en prod | Retraining peri√≥dico, monitoring |

---

## üîê √âtica y Fairness

| Aspecto | What | C√≥mo mitigar |
|:--------|:-----|:-------------|
| **Bias** | Modelo discrimina grupos | Auditar datasets, fairness metrics |
| **Privacy** | Datos sensibles | Differential privacy, federated learning |
| **Explainability** | Black-box decisions | SHAP, LIME, feature importance |
| **Transparency** | Comunicar limitaciones | Documentar asunciones, model cards |

**Herramientas:** [SHAP](https://shap.readthedocs.io/), [LIME](https://github.com/marcotcr/lime), [Fairlearn](https://fairlearn.org/)

---

## üìö Recursos

- [fast.ai](https://www.fast.ai/)
- [Deep Learning Book - Goodfellow](https://www.deeplearningbook.org/)
- [Kaggle Learn](https://www.kaggle.com/learn)
- [Papers with Code](https://paperswithcode.com/)
- [Hugging Face Course](https://huggingface.co/learn)

---

[‚¨ÖÔ∏è Anterior: Infraestructura Cloud](./12-infraestructura-cloud.md) | [‚¨ÜÔ∏è Volver arriba](#13---machine-learning-y-deep-learning) | [‚û°Ô∏è Siguiente: Ciencia de Datos](./14-ciencia-datos.md)