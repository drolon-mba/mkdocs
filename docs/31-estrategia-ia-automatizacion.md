# 31 - Estrategia de IA y Automatizaci√≥n

> Estrategia de adopci√≥n de IA en workflows reales: cu√°ndo usar, l√≠mites, integraci√≥n en procesos.

[üè† Volver al √≠ndice](./00-indice.md)

---

## üìã √çndice R√°pido

- [ü§ñ Introducci√≥n](#introduccion)
- [üéØ Casos de Uso Pr√°cticos](#casos-de-uso-practicos)
- [üö´ L√≠mites de la IA](#limites-de-la-ia)
- [üìù Prompt Engineering Avanzado](#prompt-engineering-avanzado)
- [‚úÖ Evaluaci√≥n de Outputs](#evaluacion-de-outputs)
- [üîÑ Integraci√≥n en CI/CD](#integracion-en-cicd)
- [üìã Artefactos](#artefactos)

---

## ü§ñ Introducci√≥n

**Qu√©:** Estrategia para integrar IA en workflows de desarrollo sin perder control ni calidad.

**Por qu√©:** IA bien usada amplifica productividad 10x. Mal usada genera c√≥digo fr√°gil, inseguro y dif√≠cil de mantener.

**C√≥mo:** Definir casos de uso, l√≠mites claros, validaci√≥n rigurosa e integraci√≥n en procesos existentes.

### Filosof√≠a: IA como Amplificador, No Reemplazo

- **IA amplifica**: Un senior con IA es 10x m√°s productivo. Un junior con IA sigue siendo junior.
- **Garbage in, garbage out**: Prompts vagos ‚Üí c√≥digo mediocre
- **Validaci√≥n cr√≠tica**: NUNCA confiar ciegamente en c√≥digo generado por IA
- **Conceptos > C√≥digo**: IA genera c√≥digo, pero vos deb√©s entender qu√© hace y por qu√©

---

## üéØ Casos de Uso Pr√°cticos

### 1. Code Review Automatizado

**Qu√© hace:**

- Detectar code smells (duplicaci√≥n, complejidad ciclom√°tica alta)
- Identificar vulnerabilidades (SQL injection, XSS, secrets expuestos)
- Sugerir refactorings (extract method, rename variable)

**Herramientas:**

- **SonarQube** + IA: An√°lisis est√°tico con sugerencias contextuales
- **GitHub Copilot** en PRs: Sugerencias de mejoras
- **Custom agents**: Agentes especializados en tu stack

**Integraci√≥n:**

```yaml
# .github/workflows/ai-code-review.yml
- name: AI Code Review
  run: |
    # Analizar diff del PR
    git diff origin/main...HEAD > changes.diff
    # Enviar a agente de code review
    ai-agent code-reviewer --input changes.diff --output review.md
```

**L√≠mites:**

- ‚úÖ Detectar patterns obvios (duplicaci√≥n, complejidad)
- ‚ùå Entender contexto de negocio (por qu√© se tom√≥ una decisi√≥n)

---

### 2. Generaci√≥n de Tests

**Qu√© hace:**

- Generar unit tests para funciones puras
- Generar test cases (happy path, edge cases, error handling)
- Generar mocks y fixtures

**Ejemplo de prompt:**

```text
Genera unit tests con pytest para esta funci√≥n:

[c√≥digo]

Incluye:
- Happy path
- Edge cases (input vac√≠o, null, valores extremos)
- Error handling (excepciones esperadas)
- Mocks para dependencias externas
```

**Validaci√≥n:**

- ‚úÖ Ejecutar tests generados y verificar que pasen
- ‚úÖ Revisar coverage (debe ser >80%)
- ‚ùå Aceptar tests que solo testean implementaci√≥n (no comportamiento)

---

### 3. Documentaci√≥n Auto-Generada

**Qu√© hace:**

- Generar docstrings a partir de c√≥digo
- Generar README a partir de estructura de proyecto
- Generar API documentation (OpenAPI) a partir de c√≥digo

**Ejemplo:**

```python
# Antes (sin docstring)
def calculate_discount(price, customer_type):
    if customer_type == "premium":
        return price * 0.8
    return price * 0.9

# Despu√©s (con IA)
def calculate_discount(price: float, customer_type: str) -> float:
    """
    Calculate discounted price based on customer type.
    
    Args:
        price: Original price before discount
        customer_type: Type of customer ("premium" or "regular")
    
    Returns:
        Discounted price
    
    Raises:
        ValueError: If price is negative or customer_type is invalid
    
    Examples:
        >>> calculate_discount(100, "premium")
        80.0
        >>> calculate_discount(100, "regular")
        90.0
    """
    if price < 0:
        raise ValueError("Price cannot be negative")
    if customer_type not in ["premium", "regular"]:
        raise ValueError(f"Invalid customer type: {customer_type}")
    
    if customer_type == "premium":
        return price * 0.8
    return price * 0.9
```

---

### 4. Refactoring Asistido

**Qu√© hace:**

- Detectar c√≥digo duplicado y sugerir extracci√≥n
- Renombrar variables/funciones con nombres m√°s descriptivos
- Aplicar design patterns (Strategy, Factory, etc.)

**Ejemplo de prompt:**

```text
Refactoriza este c√≥digo aplicando el patr√≥n Strategy para eliminar el switch statement:

[c√≥digo]

Requisitos:
- Mantener misma interfaz p√∫blica
- Agregar tests para cada estrategia
- Documentar el patr√≥n aplicado
```

---

### 5. Migraci√≥n de C√≥digo

**Qu√© hace:**

- Migrar de un lenguaje a otro (JS ‚Üí TS, Python 2 ‚Üí 3)
- Migrar de un framework a otro (AngularJS ‚Üí Angular, Class components ‚Üí Hooks)
- Actualizar a nuevas APIs (deprecated ‚Üí current)

**Validaci√≥n cr√≠tica:**

- üî¥ **NUNCA** migrar sin tests existentes
- üî¥ **SIEMPRE** revisar c√≥digo migrado l√≠nea por l√≠nea
- üî¥ **EJECUTAR** tests antes y despu√©s de migraci√≥n

---

## üö´ L√≠mites de la IA

### ‚ùå Qu√© NO Delegar a IA

| Tarea | Por qu√© NO |
|:------|:-----------|
| **Decisiones arquitect√≥nicas cr√≠ticas** | IA no entiende trade-offs de negocio, escalabilidad futura, constraints organizacionales |
| **Compliance y regulaciones** | IA puede generar c√≥digo que viola GDPR, HIPAA, SOC2 sin saberlo |
| **Ethical decisions** | IA no tiene moral ni contexto social (ej: features que pueden ser usadas para discriminaci√≥n) |
| **Security-critical code** | IA puede generar c√≥digo con vulnerabilidades sutiles (timing attacks, race conditions) |
| **Performance-critical code** | IA no optimiza para latency/throughput sin contexto espec√≠fico |

---

### ‚ö†Ô∏è Qu√© Delegar CON Validaci√≥n Rigurosa

| Tarea | Validaci√≥n Requerida |
|:------|:---------------------|
| **Boilerplate code** | Revisar que siga convenciones del proyecto |
| **Tests unitarios** | Ejecutar tests, revisar coverage, verificar que testean comportamiento (no implementaci√≥n) |
| **Documentaci√≥n** | Revisar precisi√≥n t√©cnica, claridad, ejemplos correctos |
| **Refactoring** | Ejecutar tests, revisar que no cambie comportamiento |

---

## üìù Prompt Engineering Avanzado

### Chain-of-Thought (CoT)

Hacer que la IA "piense en voz alta" antes de generar c√≥digo.

**Ejemplo:**

```text
Antes de generar c√≥digo, explica paso a paso:
1. Qu√© problema estamos resolviendo
2. Qu√© alternativas consideraste
3. Por qu√© elegiste esta soluci√≥n
4. Qu√© trade-offs tiene

Luego genera el c√≥digo.
```

**Resultado:** C√≥digo m√°s pensado, con mejor contexto.

---

### Few-Shot Learning

Dar ejemplos de lo que quer√©s antes de pedir la tarea.

**Ejemplo:**

```text
Genera unit tests siguiendo este estilo:

# Ejemplo 1:
def test_calculate_discount_premium_customer():
    # Given
    price = 100
    customer_type = "premium"
    
    # When
    result = calculate_discount(price, customer_type)
    
    # Then
    assert result == 80.0

# Ejemplo 2:
def test_calculate_discount_invalid_customer_type():
    # Given
    price = 100
    customer_type = "invalid"
    
    # When / Then
    with pytest.raises(ValueError, match="Invalid customer type"):
        calculate_discount(price, customer_type)

Ahora genera tests para esta funci√≥n:
[c√≥digo]
```

---

### Retrieval-Augmented Generation (RAG)

Proveer contexto relevante antes de generar c√≥digo.

**Ejemplo:**

```text
Contexto del proyecto:
- Stack: FastAPI + PostgreSQL + SQLAlchemy
- Convenciones: 
  - Usar Pydantic para validaci√≥n
  - Usar dependency injection para DB session
  - Tests con pytest + pytest-asyncio

Genera un endpoint CRUD para la entidad Product siguiendo estas convenciones.
```

---

## ‚úÖ Evaluaci√≥n de Outputs

### AI Output Validation Rubric

| Criterio | ‚úÖ Pasa | ‚ùå Falla |
|:---------|:--------|:---------|
| **Correctness** | C√≥digo compila/ejecuta sin errores | Syntax errors, runtime errors |
| **Security** | No vulnerabilidades (OWASP Top 10) | SQL injection, XSS, secrets expuestos |
| **Performance** | No bottlenecks obvios (N+1 queries, loops innecesarios) | Complejidad O(n¬≤) donde O(n) es posible |
| **Maintainability** | C√≥digo legible, nombres descriptivos, funciones peque√±as | Funciones >50 l√≠neas, nombres cr√≠pticos |
| **Testing** | Tests incluidos, coverage >80% | Sin tests o tests que no testean comportamiento |
| **Documentation** | Docstrings claros, ejemplos correctos | Sin docs o docs incorrectos |

---

### Checklist de Validaci√≥n

Antes de aceptar c√≥digo generado por IA:

- [ ] **Compilar/ejecutar**: ¬øEl c√≥digo corre sin errores?
- [ ] **Tests**: ¬øHay tests? ¬øPasan? ¬øCoverage >80%?
- [ ] **Security scan**: ¬øPas√≥ SAST/DAST? ¬øNo hay secrets expuestos?
- [ ] **Code review**: ¬øUn humano revis√≥ el c√≥digo?
- [ ] **Performance**: ¬øNo hay bottlenecks obvios?
- [ ] **Convenciones**: ¬øSigue el style guide del proyecto?
- [ ] **Documentaci√≥n**: ¬øEst√° documentado? ¬øEs preciso?

---

## üîÑ Integraci√≥n en CI/CD

### Pre-Commit Hooks con IA

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: ai-code-review
        name: AI Code Review
        entry: ai-agent code-reviewer
        language: system
        pass_filenames: true
        
      - id: ai-test-generation
        name: AI Test Generation
        entry: ai-agent test-generator --check-coverage
        language: system
        files: \.py$
```

---

### Code Suggestions en PRs

```yaml
# .github/workflows/pr-review.yml
name: AI PR Review

on:
  pull_request:
    types: [opened, synchronize]

jobs:
  ai-review:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: AI Code Review
        run: |
          # Obtener diff del PR
          git diff origin/${{ github.base_ref }}...HEAD > pr.diff
          
          # Enviar a agente de code review
          ai-agent code-reviewer --input pr.diff --output review.md
          
      - name: Post Review Comment
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const review = fs.readFileSync('review.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: review
            });
```

---

### Automated Refactoring

```yaml
# .github/workflows/auto-refactor.yml
name: Auto Refactor

on:
  schedule:
    - cron: '0 2 * * 1'  # Lunes a las 2am

jobs:
  refactor:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Detect Code Smells
        run: |
          ai-agent refactorer --detect-smells --output smells.json
          
      - name: Apply Refactorings
        run: |
          ai-agent refactorer --apply-fixes --input smells.json
          
      - name: Run Tests
        run: pytest
        
      - name: Create PR
        if: success()
        uses: peter-evans/create-pull-request@v5
        with:
          title: "ü§ñ Automated Refactoring"
          body: "AI-suggested refactorings. Review carefully before merging."
          branch: auto-refactor
```

---

## üìã Artefactos

### AI Adoption Checklist

Decidir si usar IA para una tarea:

| Criterio | Usar IA | NO usar IA |
|:---------|:--------|:-----------|
| **Repetitividad** | Tarea repetitiva (boilerplate, tests) | Tarea √∫nica, creativa |
| **Riesgo** | Bajo riesgo (c√≥digo no cr√≠tico) | Alto riesgo (security, compliance) |
| **Complejidad** | Complejidad baja-media | Complejidad alta (arquitectura) |
| **Contexto** | Contexto claro, bien definido | Contexto ambiguo, muchas variables |
| **Validaci√≥n** | F√°cil de validar (tests, linters) | Dif√≠cil de validar (ethical decisions) |

**Ejemplo:**

- ‚úÖ **Usar IA**: Generar unit tests para funci√≥n pura
- ‚ùå **NO usar IA**: Decidir arquitectura de microservices vs monolito

---

### Prompt Template Library

#### Template: Code Review

```text
Revisa este c√≥digo y proporciona feedback organizado por prioridad:

[c√≥digo]

Checklist:
- Correctness (l√≥gica, edge cases)
- Security (OWASP Top 10)
- Performance (bottlenecks, complejidad)
- Maintainability (legibilidad, nombres, funciones peque√±as)
- Testing (coverage, calidad de tests)

Formato de salida:
## Critical Issues (must fix)
- [issue 1]

## Warnings (should fix)
- [issue 1]

## Suggestions (consider improving)
- [issue 1]
```

---

#### Template: Test Generation

```text
Genera unit tests para esta funci√≥n:

[c√≥digo]

Requisitos:
- Framework: [pytest/jest/junit]
- Incluir:
  - Happy path
  - Edge cases (input vac√≠o, null, valores extremos)
  - Error handling (excepciones esperadas)
  - Mocks para dependencias externas
- Estilo: Given-When-Then
- Coverage objetivo: >80%
```

---

#### Template: Documentation

```text
Genera documentaci√≥n para este c√≥digo:

[c√≥digo]

Formato:
- Docstring con descripci√≥n clara
- Args con tipos y descripciones
- Returns con tipo y descripci√≥n
- Raises con excepciones posibles
- Examples con casos de uso reales

Audiencia: [junior/senior/stakeholders]
```

---

#### Template: Refactoring

```text
Refactoriza este c√≥digo:

[c√≥digo]

Objetivos:
- Aplicar [patr√≥n de dise√±o espec√≠fico]
- Reducir complejidad ciclom√°tica
- Eliminar duplicaci√≥n
- Mejorar nombres (variables, funciones)

Constraints:
- Mantener misma interfaz p√∫blica
- No cambiar comportamiento (tests deben seguir pasando)
- Agregar tests si no existen
```

---

## üìö Recursos

- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Library](https://docs.anthropic.com/claude/prompt-library)
- [GitHub Copilot Best Practices](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/)
- [Google AI Code Review](https://ai.google/research/pubs/pub49101)

---

[‚¨ÖÔ∏è Anterior: Prompts y Agentes](./30-prompts-agentes.md) | [‚¨ÜÔ∏è Volver arriba](#31-estrategia-de-ia-y-automatizacion) | [‚û°Ô∏è Siguiente: √âtica y Gobernanza de IA](./32-etica-gobernanza-ia.md)
